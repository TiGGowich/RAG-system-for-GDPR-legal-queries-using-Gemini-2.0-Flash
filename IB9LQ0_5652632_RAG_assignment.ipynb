{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Instructions for Running This Assignment in Google Colab**\n",
        "\n",
        "To ensure this notebook runs correctly, please follow these steps:\n",
        "\n",
        "    Unzip the Submission File: Extract all contents of the submitted .zip file. You should find the IB9LQ0_5652632_RAG_assignment.pdf report, your Colab notebook (IB9LQ0_5652632_RAG_assignment.ipynb), and the three PDF corpus files (CNIL practice guide to GDPR_removed.pdf, GDPR EU_removed.pdf, ICO guide to GDPR_removed.pdf).\n",
        "\n",
        "    Open the Notebook in Google Colab: Upload and open your_notebook_name.ipynb in your Google Colab environment.\n",
        "\n",
        "    Set Up Your Google Gemini API Key (One-Time Setup):\n",
        "        This notebook uses the Google Gemini API. You will need your own Gemini API key for this to work.\n",
        "        If you don't have one, you can get one from the Google AI Studio.\n",
        "        In Google Colab, on the left sidebar, click the 🔑 Secrets icon.\n",
        "\n",
        "    Click \"Add new secret\".\n",
        "    Set the Name of the secret to GOOGLE_API_KEY (case-sensitive).\n",
        "    Paste your Gemini API key into the Value field.\n",
        "    Ensure \"Notebook access\" is toggled ON for this notebook.\n",
        "\n",
        "Run the Notebook Cells Sequentially:\n",
        "\n",
        "    Initial Setup Cell (Installs Libraries): Run the first cell to install all necessary Python libraries.\n",
        "    File Upload Cell: When you run the cell that prompts for file upload, a file selection dialog will appear. Please select the following three PDF corpus files from your unzipped submission:\n",
        "        CNIL practice guide to GDPR_removed.pdf\n",
        "        GDPR EU_removed.pdf\n",
        "        ICO guide to GDPR_removed.pdf (These are your corpus documents for the RAG system.)\n",
        "    Continue Running: Proceed to run the rest of the notebook cells in order. The notebook will automatically load the uploaded PDFs, create document chunks, generate embeddings, set up the retriever, and perform the RAG queries."
      ],
      "metadata": {
        "id": "mSDmGNuBf-Jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing & Reading Files**"
      ],
      "metadata": {
        "id": "cZHUL9kqSYu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Python's standard library to work with file paths and directories\n",
        "import os\n",
        "\n",
        "# Install the required Python libraries\n",
        "# - langchain: for building the RAG pipeline\n",
        "# - langchain-community: community-built integrations (i.e. PDF loading)\n",
        "# - pypdf: for reading and parsing PDF documents\n",
        "# - sentence-transformers: to later create embeddings\n",
        "# - chromadb: vector database for storing and retrieving chunks semantically\n",
        "!pip install langchain langchain-community pypdf sentence-transformers chromadb -q\n",
        "\n",
        "# Import the PDF loader from the langchain_community package\n",
        "# Reads PDF files and breaks them down page by page into structured text\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# For file upload\n",
        "from google.colab import files\n",
        "\n",
        "# --- Step 1: Instructions and File Upload for the Marker ---\n",
        "print(\"IMPORTANT: Please upload your 3 PDF corpus files (CNIL, GDPR EU, ICO Guide) now.\")\n",
        "print(\"A file selection dialog will appear. Please select the following files:\")\n",
        "print(\"  - CNIL practice guide to GDPR_removed.pdf\")\n",
        "print(\"  - GDPR EU_removed.pdf\")\n",
        "print(\"  - ICO guide to GDPR_removed.pdf\")\n",
        "\n",
        "uploaded = files.upload() # Will open a file selection dialog in your browser\n",
        "\n",
        "# Optional: Confirm uploaded files\n",
        "print(\"\\nFiles uploaded by user:\")\n",
        "for fn in uploaded.keys():\n",
        "    print(f'- \"{fn}\"')\n",
        "\n",
        "# --- Step 2: Define the folder path within Colab's local environment ---\n",
        "# Once uploaded via files.upload(), the PDFs are placed directly in /content/\n",
        "pdf_folder = \"/content/\"\n",
        "\n",
        "# --- Step 3: Your existing code to load PDF pages from the folder ---\n",
        "# Create an empty list to hold all the pages from all PDFs\n",
        "docs = []\n",
        "\n",
        "# Loop through each file in the folder\n",
        "for filename in os.listdir(pdf_folder):\n",
        "    # Only load files that end in '.pdf' and match specific filenames\n",
        "    # This prevents loading other temporary files that might be in /content/\n",
        "    if filename in [\"CNIL practice guide to GDPR_removed.pdf\",\n",
        "                    \"GDPR EU_removed.pdf\",\n",
        "                    \"ICO guide to GDPR_removed.pdf\"] and filename.endswith(\".pdf\"):\n",
        "        # Create a PDF loader for the current file\n",
        "        loader = PyPDFLoader(os.path.join(pdf_folder, filename))\n",
        "\n",
        "        # Load the PDF into pages and add to the docs list\n",
        "        # Each page is treated as a separate 'Document' object\n",
        "        docs.extend(loader.load())\n",
        "\n",
        "# Print out how many total pages were loaded from all PDFs\n",
        "print(f\"\\nLoaded {len(docs)} pages from folder: {pdf_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "zKJu9dnlP0EN",
        "outputId": "6320408b-3bc2-40b8-b97f-e3f5433588e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: Please upload your 3 PDF corpus files (CNIL, GDPR EU, ICO Guide) now.\n",
            "A file selection dialog will appear. Please select the following files:\n",
            "  - CNIL practice guide to GDPR_removed.pdf\n",
            "  - GDPR EU_removed.pdf\n",
            "  - ICO guide to GDPR_removed.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b584cc2a-6618-4990-863a-25d125252861\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b584cc2a-6618-4990-863a-25d125252861\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CNIL practice guide to GDPR_removed.pdf to CNIL practice guide to GDPR_removed (1).pdf\n",
            "Saving GDPR EU_removed.pdf to GDPR EU_removed (1).pdf\n",
            "Saving ICO guide to GDPR_removed.pdf to ICO guide to GDPR_removed (1).pdf\n",
            "\n",
            "Files uploaded by user:\n",
            "- \"CNIL practice guide to GDPR_removed (1).pdf\"\n",
            "- \"GDPR EU_removed (1).pdf\"\n",
            "- \"ICO guide to GDPR_removed (1).pdf\"\n",
            "\n",
            "Loaded 465 pages from folder: /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Creating document chunks**\n",
        "with Semantic Chunking\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NsY-sqF0eEfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "# Download the necessary 'punkt_tab' resource for the NLTKTextSplitter\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# Use NLTK sentence-based splitter instead of character-based\n",
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "\n",
        "# Create semantic text splitter\n",
        "text_splitter = NLTKTextSplitter(\n",
        "    chunk_size=800,         # Target max token length\n",
        "    chunk_overlap=100       # To preserve cross-sentence context\n",
        ")\n",
        "\n",
        "# Apply to already-loaded 'docs' list\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Print total number of semantic chunks created\n",
        "print(f\"Split into {len(splits)} semantically coherent chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNKqdLJeeOph",
        "outputId": "2f6e7564-a661-4791-bb87-50903d5add07",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1140, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 930, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 927, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1549, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1252, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 862, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1311, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1001, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 951, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 811, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1034, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 874, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1022, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1068, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1443, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1481, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 810, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 828, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 860, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 817, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2931, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1099, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 895, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 948, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1178, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1284, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1571, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1518, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1412, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 988, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 837, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1008, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 816, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2018, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 982, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 883, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1105, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1111, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 966, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 827, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1731, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1169, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2767, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1318, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1757, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 826, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1084, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1027, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 905, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1260, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1265, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1716, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2529, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 868, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1846, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 938, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 818, which is longer than the specified 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 1856 semantically coherent chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 3 chunks to visually inspect the structure\n",
        "for i, split in enumerate(splits[:3]):\n",
        "    print(f\"--- Chunk {i + 1} ---\")\n",
        "    print(split.page_content)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LZU3fASQejD1",
        "outputId": "ec53cc22-12fd-48e2-ed61-93d018fee49f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chunk 1 ---\n",
            "4\n",
            "FOREWORD\n",
            "Security is an essential part of the protection of personal data.\n",
            "\n",
            "It is binding on any data controller and \n",
            "data processor through Article 32 of the General Data Protection Regulation1  (GDPR).\n",
            "\n",
            "In principle, \n",
            "each processing operation must be subjected to a set of security measures decided according to the \n",
            "context, namely “useful precautions, having regard to the nature of the data and the risks presented \n",
            "by the processing” ( Article 121 of the French Data Protection Act 2 ).\n",
            "\n",
            "The GDPR specifies that the \n",
            "protection of personal data requires taking “appropriate technical and organisational measures to \n",
            "ensure a level of security appropriate to the risk” for the rights and freedoms of natural persons, \n",
            "including their privacy.\n",
            "\n",
            "--- Chunk 2 ---\n",
            "To assess the measures to be put in place, two complementary approaches are to be deployed:\n",
            " – the establishment of a security base incorporating good practices resulting from years of      \n",
            "capitalising on hygiene and IT security (e.g.\n",
            "\n",
            ": regulations, standards, guides).\n",
            "\n",
            "This base aims to \n",
            "address the most common risks;\n",
            " – the risk analysis3  for the persons concerned by the processing, which aims to identify and assess \n",
            "the risks specific to the treatment.\n",
            "\n",
            "Such an analysis supports objective decision-making on the \n",
            "treatment of these risks and the identification of necessary and context-appropriate measures.\n",
            "\n",
            "--- Chunk 3 ---\n",
            "However, it is difficult for non-specialists in IT security to implement such an approach and to ensure \n",
            "that the level of security of the processing for which they are responsible is sufficient.\n",
            "\n",
            "To help with compliance, this guide presents a set of recommendations grouped by thematic \n",
            "factsheets.\n",
            "\n",
            "Each factsheet is structured in three sections:\n",
            " – basic precautions, which incorporate essential good practices;\n",
            " – bad trend practices, which should be avoided;\n",
            " – additional measures, to go further4 .\n",
            "\n",
            "Each factsheet can be read separately from the others: references are given when another factsheet.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Creating embeddings & vector storage**"
      ],
      "metadata": {
        "id": "6t5vdK61zBM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm -q\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Load BGE-base embedding model (768 dimensions)\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\")\n",
        "\n",
        "# Vectorstore setup\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import shutil, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "persist_directory = \"db_bge_base_embeddings\"\n",
        "\n",
        "# Clear old vectorstore if exists\n",
        "if os.path.exists(persist_directory):\n",
        "    shutil.rmtree(persist_directory)\n",
        "\n",
        "# Embed chunks\n",
        "batch_size = 300\n",
        "print(f\"📦 Embedding {len(splits)} chunks with BGE-base...\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits[:batch_size],\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "vectorstore.persist()\n",
        "\n",
        "for i in tqdm(range(batch_size, len(splits), batch_size), desc=\"Embedding batches\"):\n",
        "    end = min(i + batch_size, len(splits))\n",
        "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
        "    vectorstore.add_documents(splits[i:end])\n",
        "    vectorstore.persist()\n",
        "\n",
        "print(f\"All chunks embedded and stored in '{persist_directory}' with BGE-base.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBUL3xGD9pTQ",
        "outputId": "3ab14639-f2b6-4f60-a2bf-3cdbd7f09b2a",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-35d55762f6e5>:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Embedding 1856 chunks with BGE-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-35d55762f6e5>:31: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n",
            "Embedding batches:   0%|          | 0/6 [00:00<?, ?it/s]<ipython-input-4-35d55762f6e5>:35: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
            "Embedding batches: 100%|██████████| 6/6 [17:18<00:00, 173.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All chunks embedded and stored in 'db_bge_base_embeddings' with BGE-base.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conduct an initial test query to check if chunks can be retrieved properly"
      ],
      "metadata": {
        "id": "aeH1l35pHw8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "8# Set up the retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Create an interactive input box in Google Colab\n",
        "query = \"What rights does an individual have under the GDPR regarding their personal data?\"  #@param {type:\"string\"}\n",
        "\n",
        "# Perform retrieval\n",
        "results = retriever.invoke(query)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\n🔍 Retrieval for: '{query}'\")\n",
        "print(f\"Retrieved {len(results)} documents:\\n\")\n",
        "\n",
        "# Show retrieved content\n",
        "for i, doc in enumerate(results):\n",
        "    print(f\"--- Document {i+1} ---\")\n",
        "    print(doc.page_content[:500])  # Show preview of the text\n",
        "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxNgplfmFBQ6",
        "outputId": "b387c92a-6181-4260-f788-157d15a56f7e",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Retrieval for: 'What rights does an individual have under the GDPR regarding their personal data?'\n",
            "Retrieved 4 documents:\n",
            "\n",
            "--- Document 1 ---\n",
            "Individual rights\n",
            "The UK GDPR provides the following rights for individuals:\n",
            "The right to be informed1.\n",
            "\n",
            "The right of access2.\n",
            "\n",
            "The right to rectification3.\n",
            "\n",
            "The right to erasure4.\n",
            "\n",
            "The right to restrict processing5.\n",
            "\n",
            "The right to data portability6.\n",
            "\n",
            "The right to object7.\n",
            "\n",
            "Rights in relation to automated decision making and profiling.8.\n",
            "\n",
            "This part of the guide explains these rights.\n",
            "\n",
            "14 October 2022 - 1.1.17 99\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Document 2 ---\n",
            "The right to withdraw consent ✓✓✓✓ ✓✓✓✓\n",
            "The right to lodge a complaint with a\n",
            "supervisory authority\n",
            "✓✓✓✓ ✓✓✓✓ \n",
            "The source of the personal data  ✓✓✓✓\n",
            "The details of whether individuals are under a\n",
            "statutory or contractual obligation to provide\n",
            "the personal data\n",
            "✓✓✓✓  \n",
            "The details of the existence of automated\n",
            "decision-making, including profiling\n",
            "✓✓✓✓ ✓✓✓✓\n",
            "When should we provide privacy information?\n",
            "\n",
            "When you collect personal data from the individual it relates to, you must provide them with priva\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Document 3 ---\n",
            "However, you may be able to provide some personal data in response to the\n",
            "Relevant provisions in the UK GDPR (the exempt provisions) - See UK GDPR Articles 5, 13(1)-(3),\n",
            "14(1)-(4), 15(1)-(3), 17(1)-(2), 18(1) and 21(1) \n",
            "External link\n",
            "\n",
            "Relevant provisions in the UK GDPR - See UK GDPR Articles 5, 13 and 14 and Recitals 39, 60 and 61 \n",
            "External link\n",
            "\n",
            "14 October 2022 - 1.1.17 346\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Document 4 ---\n",
            "Can we ask an individual for ID?\n",
            "\n",
            "What is the right to restrict processing?\n",
            "\n",
            "Article 18 of the UK GDPR gives individuals the right to restrict the processing of their personal data in\n",
            "certain circumstances.\n",
            "\n",
            "This means that an individual can limit the way that an organisation uses their data.\n",
            "\n",
            "This is an alternative to requesting the erasure of their data.\n",
            "\n",
            "Individuals have the right to restrict the processing of their personal data where they have a particular\n",
            "reason for wanting the restriction\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. LLM setup & RAG pipeline**\n",
        "with Reranking\n",
        "---"
      ],
      "metadata": {
        "id": "9Ge-JOZRRGT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the reranker\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "# Install the retriever\n",
        "!pip install rank_bm25\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.retrievers import BM25Retriever\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.schema import Document\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\")\n",
        "persist_directory = \"db_bge_base_embeddings\"\n",
        "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)"
      ],
      "metadata": {
        "id": "0UsmMXGk4Y9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285b878f-4796-4058-9cf4-d340edd89756",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Querying**\n",
        "Gemini API key is required - named 'GOOGLE_API_KEY'\n",
        "---"
      ],
      "metadata": {
        "id": "d_ENj3br8dDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load reranker\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import for Colab secrets access\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "sRy5cbL3ePit"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your query\n",
        "query = \"What are the lawful bases for processing personal data under GDPR?\" #@param {type:\"string\"}\n",
        "\n",
        "reranker_name = \"BAAI/bge-reranker-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(reranker_name)\n",
        "reranker = AutoModelForSequenceClassification.from_pretrained(reranker_name)\n",
        "reranker.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "reranker.to(device)\n",
        "\n",
        "# Step 1: Build a keyword-based BM25Retriever (from the same docs used in embedding)\n",
        "bm25_retriever = BM25Retriever.from_documents(splits)  # 'splits' = your chunked documents\n",
        "bm25_retriever.k = 10  # You can adjust\n",
        "\n",
        "# Step 2: Build a vector-based retriever from the semantic DB\n",
        "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# Step 3: Define hybrid retriever\n",
        "def hybrid_retrieve(query):\n",
        "    bm25_docs = bm25_retriever.get_relevant_documents(query)\n",
        "    vector_docs = vector_retriever.get_relevant_documents(query)\n",
        "\n",
        "    # Combine & deduplicate (based on content)\n",
        "    all_docs = {doc.page_content: doc for doc in bm25_docs + vector_docs}\n",
        "    return list(all_docs.values())\n",
        "\n",
        "# Step 4: Apply reranker to hybrid results\n",
        "def rerank_docs(query, docs, top_n=8):\n",
        "    inputs = [\n",
        "        tokenizer(query, doc.page_content, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "        for doc in docs\n",
        "    ]\n",
        "    with torch.no_grad():\n",
        "        scores = []\n",
        "        for i, inp in enumerate(inputs):\n",
        "            output = reranker(**inp)\n",
        "            score = output.logits[0].item()\n",
        "            scores.append((score, docs[i]))\n",
        "    reranked = sorted(scores, key=lambda x: x[0], reverse=True)[:top_n]\n",
        "    return [doc for _, doc in reranked]\n",
        "\n",
        "initial_docs = hybrid_retrieve(query)\n",
        "retrieved_docs = rerank_docs(query, initial_docs)\n",
        "\n",
        "# Context line\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "# Prompt for Gemini\n",
        "prompt = f\"\"\"\n",
        "You are an expert legal assistant with detailed knowledge of data protection law,\n",
        "especially the General Data Protection Regulation (GDPR). Answer the following question\n",
        "clearly and precisely using only the information provided in the context below.\n",
        "\n",
        "If the answer is not found in the context, do not hallucinate. If the answer is not clearly available from\n",
        "the context provided, say \"The information is not available in the context provided.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "# Use Gemini\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import GenerationConfig\n",
        "\n",
        "# Get API key\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))  # Replace if needed\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "generation_config = GenerationConfig(max_output_tokens=1024, temperature=0.3)\n",
        "response = model.generate_content(prompt, generation_config=generation_config)\n",
        "\n",
        "# Output\n",
        "print(\"🔍 Query:\")\n",
        "print(query)\n",
        "print(\"\\n🧠 Gemini's Answer:\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "tvNNd3xIROpk",
        "outputId": "75d9449a-3e4a-4e37-b375-4b91f23f64ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9dce8001c155>:20: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  bm25_docs = bm25_retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Query:\n",
            "What are the lawful bases for processing personal data under GDPR?\n",
            "\n",
            "🧠 Gemini's Answer:\n",
            "The lawful bases for processing are set out in Article 6 of the UK GDPR. At least one of these must apply whenever you process personal data: (a) Consent: the individual has given clear consent for you to process their personal data for a specific purpose. Article 6(1)(d) provides a lawful basis for processing where processing is necessary in order to protect the vital interests of the data subject or of another natural person. There are six available lawful bases for processing.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View retrieved chunks\n",
        "for i, doc in enumerate(retrieved_docs):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\")\n",
        "    print(doc.page_content[:1000])  # print first 1000 characters\n",
        "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz72DQOZWh1m",
        "outputId": "3b212427-de82-4523-9630-c3a33978d298",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Chunk 1 ---\n",
            "In brief\n",
            "What are the lawful bases for processing?\n",
            "\n",
            "When is processing ‘necessary’?\n",
            "\n",
            "Why is the lawful basis for processing important?\n",
            "\n",
            "How do we decide which lawful basis applies?\n",
            "\n",
            "Is this different for public authorities?\n",
            "\n",
            "Can we change our lawful basis?\n",
            "\n",
            "What happens if we have a new purpose?\n",
            "\n",
            "How should we document our lawful basis?\n",
            "\n",
            "What do we need to tell people?\n",
            "\n",
            "What about special category data?\n",
            "\n",
            "What about criminal offence data?\n",
            "\n",
            "What are the lawful bases for processing?\n",
            "\n",
            "The lawful bases for processing are set out in Article 6 of the UK GDPR.\n",
            "\n",
            "At least one of these must apply\n",
            "whenever you process personal data:\n",
            "(a) Consent: the individual has given clear consent for you to process their personal data for a specific\n",
            "purpose.\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 2 ---\n",
            "What are ‘vital interests’?\n",
            "\n",
            "When is the vital interests basis likely to apply?\n",
            "\n",
            "What else should we consider?\n",
            "\n",
            "What does the UK GDPR say?\n",
            "\n",
            "Article 6(1)(d) provides a lawful basis for processing where:\n",
            "Recital 46 provides some further guidance:\n",
            "What are ‘vital interests’?\n",
            "\n",
            "\n",
            "“processing is necessary in order to protect the vital interests of the data subject or of another natural\n",
            "person”.\n",
            "\n",
            "\n",
            "“The processing of personal data should also be regarded as lawful where it is necessary to protect an\n",
            "interest which is essential for the life of the data subject or that of another natural person.\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 3 ---\n",
            "See our guidance on the other lawful\n",
            "bases for more information.\n",
            "\n",
            "Remember that the UK GDPR specifically says that further processing for certain purposes should be\n",
            "considered to be compatible with your original purpose.\n",
            "\n",
            "This means that if you originally processed the\n",
            "personal data for a relevant task or function, you do not need a separate lawful basis for any further\n",
            "processing for:\n",
            "archiving purposes in the public interest;\n",
            "scientific research purposes; or\n",
            "statistical purposes.\n",
            "\n",
            "If you are processing special category data, you also need to identify an additional condition for processing\n",
            "this type of data.\n",
            "\n",
            "The Data Protection Act 2018 includes specific conditions for parliamentary, statutory or\n",
            "governmental functions in the substantial public interest.\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Lawful basis for processing\n",
            "At a glance\n",
            "You must have a valid lawful basis in order to process personal data.\n",
            "\n",
            "There are six available lawful bases for processing.\n",
            "\n",
            "No single basis is ’better’ or more important than the\n",
            "others – which basis is most appropriate to use will depend on your purpose and relationship with the\n",
            "individual.\n",
            "\n",
            "Most lawful bases require that processing is ‘necessary’ for a specific purpose.\n",
            "\n",
            "If you can reasonably\n",
            "achieve the same purpose without the processing, you won’t have a lawful basis.\n",
            "\n",
            "You must determine your lawful basis before you begin processing, and you should document it.\n",
            "\n",
            "We\n",
            "have an interactive tool to help you.\n",
            "\n",
            "Take care to get it right first time - you should not swap to a different lawful basis at a later date without\n",
            "good reason.\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 5 ---\n",
            "☐ The lawful basis for the processing.\n",
            "\n",
            "☐ The legitimate interests for the processing (if applicable).\n",
            "\n",
            "☐ The categories of personal data obtained (if the personal data is not obtained from the individual\n",
            "it relates to).\n",
            "\n",
            "☐ The recipients or categories of recipients of the personal data.\n",
            "\n",
            "☐ The details of transfers of the personal data to any third countries or international organisations\n",
            "(if applicable).\n",
            "\n",
            "☐ The retention periods for the personal data.\n",
            "\n",
            "☐ The rights available to individuals in respect of the processing.\n",
            "\n",
            "☐ The right to withdraw consent (if applicable).\n",
            "\n",
            "☐ The right to lodge a complaint with a supervisory authority.\n",
            "\n",
            "☐ The source of the personal data (if the personal data is not obtained from the individual it relates\n",
            "to).\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 6 ---\n",
            "You must not adopt a one-size-fits-all approach.\n",
            "\n",
            "No one basis should be seen as always better, safer or\n",
            "more important than the others, and there is no hierarchy in the order of the list in the UK GDPR.\n",
            "\n",
            "Several of the lawful bases relate to a particular specified purpose – a legal obligation, performing a\n",
            "contract with the individual, protecting someone’s vital interests, or performing your public tasks.\n",
            "\n",
            "If you are\n",
            "processing for these purposes then the appropriate lawful basis may well be obvious, so it is helpful to\n",
            "consider these first.\n",
            "\n",
            "In other cases you are likely to have a choice between using legitimate interests or consent.\n",
            "\n",
            "You need to\n",
            "give some thought to the wider context, including:\n",
            "Who does the processing benefit?\n",
            "\n",
            "Would individuals expect this processing to take place?\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 7 ---\n",
            "The UK GDPR applies to the processing of personal data that is:\n",
            "wholly or partly by automated means; or\n",
            "the processing other than by automated means of personal data which forms part of, or is intended\n",
            "to form part of, a filing system.\n",
            "\n",
            "Personal data only includes information relating to natural persons who:\n",
            "can be identified or who are identifiable, directly from the information in question; or\n",
            "who can be indirectly identified from that information in combination with other information.\n",
            "\n",
            "Personal data may also include special categories of personal data or criminal conviction and offences\n",
            "data.\n",
            "\n",
            "These are considered to be more sensitive and you may only process them in more limited\n",
            "circumstances.\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n",
            "\n",
            "--- Chunk 8 ---\n",
            "To ensure that your processing is lawful, you need\n",
            "to identify an Article 6 basis for processing.\n",
            "\n",
            "In addition, you can only process special category data if you can meet one of the specific conditions in\n",
            "Article 9 of the UK GDPR.\n",
            "\n",
            "You need to consider the purposes of your processing and identify which of these\n",
            "conditions are relevant.\n",
            "\n",
            "other obligations around data minimisation, security, and appointing Data Protection Officers\n",
            "(DPOs) and representatives.\n",
            "\n",
            "14 October 2022 - 1.1.17 69\n",
            "Source: /content/ICO guide to GDPR_removed.pdf\n"
          ]
        }
      ]
    }
  ]
}